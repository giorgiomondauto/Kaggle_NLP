{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Bert pretrained model and use on text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n",
      "['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "print(len(tokenizer))\n",
    "\n",
    "# Tokenize input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson  was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
      "          1037, 13997, 11510,   102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "# assert tokenized_text == ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', '[MASK]', 'was', 'a', 'puppet', '##eer', '[SEP]']\n",
    "\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1,1,1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "print(tokens_tensor)\n",
    "print(segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_index 27227\n",
      "Predicted token is: henson\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "# print(model)\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor\n",
    "segments_tensors = segments_tensors\n",
    "# model\n",
    "\n",
    "# Predict all tokens\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "    outputs_no_tokentype = model(tokens_tensor)\n",
    "\n",
    "    predictions = outputs[0]\n",
    "    prediction_no = outputs_no_tokentype[0]\n",
    "\n",
    "# confirm we were able to predict 'henson'\n",
    "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "print('predicted_index',predicted_index)\n",
    "\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "# assert predicted_token == 'henson'\n",
    "\n",
    "print('Predicted token is:',predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 30522])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27227"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(predictions[0,8]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'henson'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([27227])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -7.8798,  -7.7874,  -7.7861,  ...,  -7.0438,  -6.7454,  -4.6013],\n",
      "        [-13.3633, -13.7694, -13.7819,  ..., -11.8128, -11.1635, -13.8906],\n",
      "        [-10.9775, -10.5383, -10.9659,  ..., -11.5549,  -8.0309,  -6.3979],\n",
      "        ...,\n",
      "        [ -5.2284,  -5.6572,  -5.3550,  ...,  -3.4507,  -3.8718,  -8.6904],\n",
      "        [ -8.5290,  -8.4146,  -9.0744,  ...,  -7.1710,  -6.9877,  -6.1301],\n",
      "        [-12.5968, -12.3769, -12.4222,  ..., -10.1020,  -9.8764,  -9.4495]])\n",
      "torch.Size([1, 14, 30522])\n",
      "27227\n",
      "henson\n",
      "weights for the token masked tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# WITH FEATURE TYPE\n",
    "print(predictions[0])\n",
    "print(predictions.shape)\n",
    "index = torch.argmax(predictions[0,8]).item()\n",
    "print(index)\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([index])[0]\n",
    "print(predicted_token)\n",
    "print('weights for the token masked',torch.argmax(predictions[0][8][27227]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -6.9487,  -6.9031,  -6.8937,  ...,  -6.2844,  -6.0191,  -4.1828],\n",
      "         [-13.8302, -14.2852, -14.2682,  ..., -12.3324, -11.4464, -14.9032],\n",
      "         [-11.7922, -11.4641, -11.7961,  ..., -12.6160,  -8.6125,  -8.0468],\n",
      "         ...,\n",
      "         [ -5.7428,  -6.1183,  -5.6917,  ...,  -3.8172,  -3.9389,  -8.3408],\n",
      "         [ -8.9365,  -8.7451,  -9.1933,  ...,  -7.8316,  -8.3316,  -3.8440],\n",
      "         [-12.2189, -12.0151, -11.9650,  ...,  -9.8166,  -9.7025,  -9.3017]]])\n",
      "torch.Size([1, 14, 30522])\n",
      "27227\n",
      "henson\n",
      "weights for the token masked without feature type tensor(15.5186)\n"
     ]
    }
   ],
   "source": [
    "# NO FEATURE TYPE\n",
    "print(prediction_no)\n",
    "print(prediction_no.shape)\n",
    "index = torch.argmax(prediction_no[0,8]).item()\n",
    "print(index)\n",
    "predicted_token_no = tokenizer.convert_ids_to_tokens([index])[0]\n",
    "print(predicted_token_no)\n",
    "print('weights for the token masked without feature type',prediction_no[0][8][27227])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27227)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(predictions[0][8])#[27227]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor([[-1.4429, -1.2701, -0.2727,  ...,  2.4877, -1.5465,  1.3952],\n",
      "        [ 0.1014, -0.5270, -0.0786,  ..., -0.4124, -1.6045,  0.6366],\n",
      "        [-1.2232,  0.3723, -0.2657,  ...,  0.5608,  1.4149, -1.4305],\n",
      "        ...,\n",
      "        [ 0.3804,  1.8699, -0.0807,  ...,  1.1345, -1.7949,  0.0969],\n",
      "        [ 0.7246,  0.8214, -0.5409,  ..., -1.4545,  0.1113,  2.1624],\n",
      "        [ 0.8984, -0.4903, -0.5561,  ...,  1.1320,  0.6060,  0.6637]],\n",
      "       requires_grad=True) torch.Size([25600, 26493])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "target tensor([ 2,  6, 19,  ...,  0, 13,  4]) torch.Size([25600])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "tensor(10.6953, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(25600,26493 , requires_grad=True)\n",
    "# input = torch.tensor([[2.,4.,3.,4,5],[2,4,3,4,5],[2,4,3,4,5]],requires_grad=True)\n",
    "print('input',input,input.shape)\n",
    "print(50*'%')\n",
    "target = torch.empty(25600,dtype=torch.long).random_(20)\n",
    "print('target',target,target.shape)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print(50*'%')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = torch.argmax(input ,1)# 25600 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    25600\n",
       "dtype: int64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(predicted==target).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((predicted==target).sum())/target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(np.array([1,2,3,4]))\n",
    "b = torch.Tensor(np.array([1,4,5,4]))\n",
    "int((a==b).sum())/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a==b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor([[ 1.7264e+00,  7.8608e-01,  2.2085e+00,  1.0811e-01,  2.5748e-01],\n",
      "        [-1.8813e-01,  5.0193e-01,  4.2372e-01, -1.9748e-03,  1.2297e+00],\n",
      "        [-7.3344e-01,  1.2675e-02, -1.3900e+00,  7.7147e-01, -2.1631e+00]],\n",
      "       requires_grad=True) torch.Size([3, 5])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "target tensor([-1,  2,  1]) torch.Size([3])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "tensor(1.5431, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "loss = nn.CrossEntropyLoss(ignore_index= -1)\n",
    "input = torch.randn(3,5 , requires_grad=True)\n",
    "print('input',input,input.shape)\n",
    "print(50*'%')\n",
    "# target = torch.empty(3,dtype=torch.long).random_(3)\n",
    "target = torch.tensor([-1, 2, 1])\n",
    "print('target',target,target.shape)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print(50*'%')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9162,  0.2505,  0.0294,  0.4328, -1.0175],\n",
       "        [-0.3876, -0.7693, -1.2163,  0.0885, -0.5896],\n",
       "        [-1.7336, -0.6171,  0.8032, -1.2351,  0.6130]], grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-input[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is to get the latest layer (weights of the tokens) out from the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bert_embedding import BertEmbedding\n",
    "import numpy as np\n",
    "\n",
    "bert_abstract = \"\"\"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers.\"\"\"\n",
    "sentences = bert_abstract.split('\\n')\n",
    "bert_embedding = BertEmbedding()\n",
    "result = bert_embedding(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(result[0][0]))\n",
    "print(np.array(result[0][0]).shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(result[0][1]))\n",
    "print(np.array(result[0][1]).shape) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
